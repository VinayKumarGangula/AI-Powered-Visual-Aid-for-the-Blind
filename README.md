# ðŸ¤– AI-Based Visual Aid for the Blind

An AI-powered assistive system developed to support blind or visually impaired individuals in navigating their surroundings using object recognition and audio feedback.

## ðŸ§  Project Overview

This project combines computer vision, natural language processing, and real-time audio generation. Built using Raspberry Pi, OpenCV, and speech synthesis APIs, the system identifies objects, signs, and faces, and converts that information into audio descriptions to assist users in real-time. Inspired by accessibility research and field-tested with 60 participants, it significantly improved task efficiency and obstacle avoidance.

## ðŸ”§ Tools & Technologies Used

- Python
- Raspberry Pi
- OpenCV
- TensorFlow / TTS APIs
- Google Text-to-Speech

## ðŸ’¡ Key Features

- Real-time object detection and tracking
- Facial recognition for known individuals
- Text-to-speech feedback for navigation and signs
- Spatial layout guidance and alerts

## ðŸŽ¯ Outcomes

- 30% improvement in user task efficiency
- 40% more accurate obstacle detection
- Tested with 60+ users in controlled environments

## ðŸš€ How to Use

> ðŸ“Œ Code, setup steps, and demo video will be uploaded.

1. Clone repo to Raspberry Pi
2. Connect USB camera and headphones
3. Run the main Python script
4. The system will detect and narrate visual surroundings

## ðŸ“¬ Contact

vinayreddygangula8@gmail.com  
[LinkedIn](https://linkedin.com/in/vinay-kumar-gangula-2b78871a7)

